{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8179239-14fa-4127-b016-14852fccee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 .gz files in C:\\Users\\lesze\\orbitfolder\\l1bfiles\\l1bfiles\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014253_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014253_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014307_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014307_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014539_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T014539_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015047_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015047_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015101_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015101_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015409_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015409_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015801_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015801_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015816_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T015816_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020139_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020139_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020518_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020518_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020542_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020542_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020905_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T020905_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021243_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021243_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021307_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021307_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021630_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T021630_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022008_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022008_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022035_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022035_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022352_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022352_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022753_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022753_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022824_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T022824_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023124_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023124_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023703_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023703_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023748_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T023748_v13_s02.fits.gz\n",
      "Extracted mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T024004_v13_s02.fits from mvn_iuv_l1b_apoapse-orbit16750-muv_20220708T024004_v13_s02.fits.gz\n",
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def extract_fits_from_gz(source_dir, destination_dir):\n",
    "    \"\"\"\n",
    "    Extracts all FITS files from .gz files in source_dir to destination_dir.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): Path to directory containing .gz files\n",
    "        destination_dir (str): Path where FITS files should be extracted\n",
    "    \"\"\"\n",
    "    # Create destination directory if it doesn't exist\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all .gz files in source directory\n",
    "    gz_files = glob.glob(os.path.join(source_dir, '*.gz'))\n",
    "    \n",
    "    if not gz_files:\n",
    "        print(f\"No .gz files found in {source_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(gz_files)} .gz files in {source_dir}\")\n",
    "    \n",
    "    for gz_path in gz_files:\n",
    "        try:\n",
    "            # Determine output filename (remove .gz extension)\n",
    "            base_name = os.path.basename(gz_path)\n",
    "            if not base_name.lower().endswith('.gz'):\n",
    "                print(f\"Skipping non-gz file: {gz_path}\")\n",
    "                continue\n",
    "                \n",
    "            output_name = base_name[:-3]  # Remove .gz\n",
    "            output_path = os.path.join(destination_dir, output_name)\n",
    "            \n",
    "            # Skip if already exists (comment out to overwrite)\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"Skipping {output_name} (already exists)\")\n",
    "                continue\n",
    "            \n",
    "            # Extract the .gz file\n",
    "            with gzip.open(gz_path, 'rb') as f_in:\n",
    "                with open(output_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "            print(f\"Extracted {output_name} from {base_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {gz_path}: {str(e)}\")\n",
    "    \n",
    "    print(\"Extraction complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get user input for paths\n",
    "    source_dir = r'C:\\Users\\lesze\\orbitfolder\\l1bfiles\\l1bfiles'\n",
    "    destination_dir = r'C:\\Users\\lesze\\orbitfolder\\orbit16750'\n",
    "    \n",
    "    # Validate paths\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print(f\"Error: Source directory '{source_dir}' does not exist\")\n",
    "    else:\n",
    "        extract_fits_from_gz(source_dir, destination_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7508781d-7e44-426c-8ef7-c3672649042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Third-party scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "# Astronomy/GIS\n",
    "from astropy.io import fits\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import os \n",
    "import pandas as pd\n",
    "from matplotlib.patches import Patch\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e002d92a-c589-4fc2-82ec-b000f557c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lesze\\AppData\\Local\\Temp\\ipykernel_16412\\1479031629.py:3: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('png')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png')\n",
    "\n",
    "# Suppress the Cartopy warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, \n",
    "                        message=\"The 'NearsidePerspective' projection does not handle elliptical globes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "484c7271-d6e2-4625-b03a-104d0f9d8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a minute\n",
    "parsed_file = pd.read_excel(r'C:/knime/cloudy_images.xlsx', index_col=0) #path to parsed classifications file\n",
    "users_removed = [] #what users should we remove?\n",
    "parsed_file = parsed_file[~parsed_file['user_name'].isin(users_removed)]\n",
    "parsed_file['ID'] = range(1, len(parsed_file)+1)\n",
    "orbit_list = [18211, 17959, 16570, 16750] #what orbits to process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d146f30f-ba95-4f55-9f69-35ae7bb05cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing orbit 18211\n",
      "processing orbit 17959\n",
      "processing orbit 16570\n",
      "processing orbit 16750\n",
      "Error processing orbit: 16750. Most likely missing FITS files or no classifications for this orbit. Check it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>subject_ids</th>\n",
       "      <th>metadata.session</th>\n",
       "      <th>metadata.started_at</th>\n",
       "      <th>...</th>\n",
       "      <th>closest_sspacecraft_alt</th>\n",
       "      <th>closest_datetime</th>\n",
       "      <th>closest_lat</th>\n",
       "      <th>closest_lon</th>\n",
       "      <th>closest_solar_zenith_angle</th>\n",
       "      <th>closest_emission_angle</th>\n",
       "      <th>closest_zenith_angle</th>\n",
       "      <th>closest_phase_angle</th>\n",
       "      <th>closest_local_time</th>\n",
       "      <th>closest_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMB60</td>\n",
       "      <td>2670845.0</td>\n",
       "      <td>5aff11e92630bab1c1bb</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-11-07 18:27:21</td>\n",
       "      <td>104282707</td>\n",
       "      <td>3ff8dc8bde930b5653d10b7788882ef6d57bfb699ce93d...</td>\n",
       "      <td>2024-11-07T18:26:16.669Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.193374e+06</td>\n",
       "      <td>2023-02-15 07:19:05</td>\n",
       "      <td>76.659787</td>\n",
       "      <td>67.986682</td>\n",
       "      <td>89.357347</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>153.450041</td>\n",
       "      <td>65.253713</td>\n",
       "      <td>3.003979</td>\n",
       "      <td>62.082045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not-logged-in-950908914f5575dc1433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950908914f5575dc1433</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-11-10 23:41:47</td>\n",
       "      <td>104284703</td>\n",
       "      <td>05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...</td>\n",
       "      <td>2024-11-10T23:30:13.622Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.133966e+06</td>\n",
       "      <td>2023-01-07 21:55:11</td>\n",
       "      <td>-28.610144</td>\n",
       "      <td>-2.542928</td>\n",
       "      <td>36.834445</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>153.438661</td>\n",
       "      <td>53.533081</td>\n",
       "      <td>13.355971</td>\n",
       "      <td>64.518383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not-logged-in-950908914f5575dc1433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950908914f5575dc1433</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-11-10 23:41:47</td>\n",
       "      <td>104284703</td>\n",
       "      <td>05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...</td>\n",
       "      <td>2024-11-10T23:30:13.622Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.133966e+06</td>\n",
       "      <td>2023-01-07 21:55:11</td>\n",
       "      <td>-28.610144</td>\n",
       "      <td>-2.542928</td>\n",
       "      <td>36.834445</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>153.438661</td>\n",
       "      <td>53.533081</td>\n",
       "      <td>13.355971</td>\n",
       "      <td>64.577601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not-logged-in-950908914f5575dc1433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950908914f5575dc1433</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-11-10 23:41:47</td>\n",
       "      <td>104284703</td>\n",
       "      <td>05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...</td>\n",
       "      <td>2024-11-10T23:30:13.622Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.133966e+06</td>\n",
       "      <td>2023-01-07 21:55:11</td>\n",
       "      <td>-28.610144</td>\n",
       "      <td>-2.542928</td>\n",
       "      <td>36.834445</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>153.438661</td>\n",
       "      <td>53.533081</td>\n",
       "      <td>13.355971</td>\n",
       "      <td>70.742225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not-logged-in-950908914f5575dc1433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950908914f5575dc1433</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-11-10 23:41:47</td>\n",
       "      <td>104284703</td>\n",
       "      <td>05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...</td>\n",
       "      <td>2024-11-10T23:30:13.622Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.133966e+06</td>\n",
       "      <td>2023-01-07 21:55:11</td>\n",
       "      <td>-28.610144</td>\n",
       "      <td>-2.542928</td>\n",
       "      <td>36.834445</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>153.438661</td>\n",
       "      <td>53.533081</td>\n",
       "      <td>13.355971</td>\n",
       "      <td>65.951832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>silentium_noctis</td>\n",
       "      <td>2784769.0</td>\n",
       "      <td>f0a2e0c0530a16433c81</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2024-12-30 04:38:57</td>\n",
       "      <td>104284523</td>\n",
       "      <td>380a485109b15f357f1587fb21d7ea2febe01da8ecb249...</td>\n",
       "      <td>2024-12-30T04:37:56.884Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.053149e+06</td>\n",
       "      <td>2022-06-11 01:43:48</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>-77.105487</td>\n",
       "      <td>112.471082</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>152.784236</td>\n",
       "      <td>66.888489</td>\n",
       "      <td>4.399493</td>\n",
       "      <td>153.020864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>anaghagaikwad</td>\n",
       "      <td>2727779.0</td>\n",
       "      <td>1cf185278a4f2619f430</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2025-01-02 05:25:12</td>\n",
       "      <td>104284523</td>\n",
       "      <td>222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...</td>\n",
       "      <td>2025-01-02T05:15:09.560Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.053149e+06</td>\n",
       "      <td>2022-06-11 01:43:48</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>-77.105487</td>\n",
       "      <td>112.471082</td>\n",
       "      <td>89.999995</td>\n",
       "      <td>152.784236</td>\n",
       "      <td>66.888489</td>\n",
       "      <td>4.399493</td>\n",
       "      <td>155.098311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>anaghagaikwad</td>\n",
       "      <td>2727779.0</td>\n",
       "      <td>1cf185278a4f2619f430</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2025-01-02 05:25:12</td>\n",
       "      <td>104284523</td>\n",
       "      <td>222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...</td>\n",
       "      <td>2025-01-02T05:15:09.560Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.319829e+06</td>\n",
       "      <td>2022-06-11 01:27:26</td>\n",
       "      <td>-64.259239</td>\n",
       "      <td>-84.019874</td>\n",
       "      <td>83.148341</td>\n",
       "      <td>13.972537</td>\n",
       "      <td>173.793680</td>\n",
       "      <td>79.427935</td>\n",
       "      <td>3.702083</td>\n",
       "      <td>0.076579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>anaghagaikwad</td>\n",
       "      <td>2727779.0</td>\n",
       "      <td>1cf185278a4f2619f430</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2025-01-02 05:25:12</td>\n",
       "      <td>104284523</td>\n",
       "      <td>222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...</td>\n",
       "      <td>2025-01-02T05:15:09.560Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.053149e+06</td>\n",
       "      <td>2022-06-11 01:43:48</td>\n",
       "      <td>-9.530926</td>\n",
       "      <td>-77.834082</td>\n",
       "      <td>108.504351</td>\n",
       "      <td>78.964228</td>\n",
       "      <td>153.325381</td>\n",
       "      <td>66.655970</td>\n",
       "      <td>4.350649</td>\n",
       "      <td>0.148963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>anaghagaikwad</td>\n",
       "      <td>2727779.0</td>\n",
       "      <td>1cf185278a4f2619f430</td>\n",
       "      <td>26820</td>\n",
       "      <td>Are Clouds Present?</td>\n",
       "      <td>40.87</td>\n",
       "      <td>2025-01-02 05:25:12</td>\n",
       "      <td>104284523</td>\n",
       "      <td>222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...</td>\n",
       "      <td>2025-01-02T05:15:09.560Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.354981e+06</td>\n",
       "      <td>2022-06-11 01:15:34</td>\n",
       "      <td>-89.593503</td>\n",
       "      <td>-74.142827</td>\n",
       "      <td>67.587520</td>\n",
       "      <td>25.940654</td>\n",
       "      <td>168.992832</td>\n",
       "      <td>93.287106</td>\n",
       "      <td>4.147274</td>\n",
       "      <td>65.630386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user_name    user_id               user_ip  \\\n",
       "0                                 LMB60  2670845.0  5aff11e92630bab1c1bb   \n",
       "1    not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
       "2    not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
       "3    not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
       "4    not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
       "..                                  ...        ...                   ...   \n",
       "560                    silentium_noctis  2784769.0  f0a2e0c0530a16433c81   \n",
       "561                       anaghagaikwad  2727779.0  1cf185278a4f2619f430   \n",
       "562                       anaghagaikwad  2727779.0  1cf185278a4f2619f430   \n",
       "563                       anaghagaikwad  2727779.0  1cf185278a4f2619f430   \n",
       "564                       anaghagaikwad  2727779.0  1cf185278a4f2619f430   \n",
       "\n",
       "     workflow_id        workflow_name  workflow_version          created_at  \\\n",
       "0          26820  Are Clouds Present?             40.87 2024-11-07 18:27:21   \n",
       "1          26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
       "2          26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
       "3          26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
       "4          26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
       "..           ...                  ...               ...                 ...   \n",
       "560        26820  Are Clouds Present?             40.87 2024-12-30 04:38:57   \n",
       "561        26820  Are Clouds Present?             40.87 2025-01-02 05:25:12   \n",
       "562        26820  Are Clouds Present?             40.87 2025-01-02 05:25:12   \n",
       "563        26820  Are Clouds Present?             40.87 2025-01-02 05:25:12   \n",
       "564        26820  Are Clouds Present?             40.87 2025-01-02 05:25:12   \n",
       "\n",
       "     subject_ids                                   metadata.session  \\\n",
       "0      104282707  3ff8dc8bde930b5653d10b7788882ef6d57bfb699ce93d...   \n",
       "1      104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
       "2      104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
       "3      104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
       "4      104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
       "..           ...                                                ...   \n",
       "560    104284523  380a485109b15f357f1587fb21d7ea2febe01da8ecb249...   \n",
       "561    104284523  222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...   \n",
       "562    104284523  222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...   \n",
       "563    104284523  222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...   \n",
       "564    104284523  222e226dfa8ed58b5b5fefbfa6022f3130f4e6568db9a3...   \n",
       "\n",
       "          metadata.started_at  ... closest_sspacecraft_alt  \\\n",
       "0    2024-11-07T18:26:16.669Z  ...            4.193374e+06   \n",
       "1    2024-11-10T23:30:13.622Z  ...            4.133966e+06   \n",
       "2    2024-11-10T23:30:13.622Z  ...            4.133966e+06   \n",
       "3    2024-11-10T23:30:13.622Z  ...            4.133966e+06   \n",
       "4    2024-11-10T23:30:13.622Z  ...            4.133966e+06   \n",
       "..                        ...  ...                     ...   \n",
       "560  2024-12-30T04:37:56.884Z  ...            4.053149e+06   \n",
       "561  2025-01-02T05:15:09.560Z  ...            4.053149e+06   \n",
       "562  2025-01-02T05:15:09.560Z  ...            4.319829e+06   \n",
       "563  2025-01-02T05:15:09.560Z  ...            4.053149e+06   \n",
       "564  2025-01-02T05:15:09.560Z  ...            4.354981e+06   \n",
       "\n",
       "       closest_datetime closest_lat closest_lon closest_solar_zenith_angle  \\\n",
       "0   2023-02-15 07:19:05   76.659787   67.986682                  89.357347   \n",
       "1   2023-01-07 21:55:11  -28.610144   -2.542928                  36.834445   \n",
       "2   2023-01-07 21:55:11  -28.610144   -2.542928                  36.834445   \n",
       "3   2023-01-07 21:55:11  -28.610144   -2.542928                  36.834445   \n",
       "4   2023-01-07 21:55:11  -28.610144   -2.542928                  36.834445   \n",
       "..                  ...         ...         ...                        ...   \n",
       "560 2022-06-11 01:43:48    0.994575  -77.105487                 112.471082   \n",
       "561 2022-06-11 01:43:48    0.994575  -77.105487                 112.471082   \n",
       "562 2022-06-11 01:27:26  -64.259239  -84.019874                  83.148341   \n",
       "563 2022-06-11 01:43:48   -9.530926  -77.834082                 108.504351   \n",
       "564 2022-06-11 01:15:34  -89.593503  -74.142827                  67.587520   \n",
       "\n",
       "     closest_emission_angle  closest_zenith_angle  closest_phase_angle  \\\n",
       "0                 89.999995            153.450041            65.253713   \n",
       "1                 89.999995            153.438661            53.533081   \n",
       "2                 89.999995            153.438661            53.533081   \n",
       "3                 89.999995            153.438661            53.533081   \n",
       "4                 89.999995            153.438661            53.533081   \n",
       "..                      ...                   ...                  ...   \n",
       "560               89.999995            152.784236            66.888489   \n",
       "561               89.999995            152.784236            66.888489   \n",
       "562               13.972537            173.793680            79.427935   \n",
       "563               78.964228            153.325381            66.655970   \n",
       "564               25.940654            168.992832            93.287106   \n",
       "\n",
       "     closest_local_time  closest_distance  \n",
       "0              3.003979         62.082045  \n",
       "1             13.355971         64.518383  \n",
       "2             13.355971         64.577601  \n",
       "3             13.355971         70.742225  \n",
       "4             13.355971         65.951832  \n",
       "..                  ...               ...  \n",
       "560            4.399493        153.020864  \n",
       "561            4.399493        155.098311  \n",
       "562            3.702083          0.076579  \n",
       "563            4.350649          0.148963  \n",
       "564            4.147274         65.630386  \n",
       "\n",
       "[565 rows x 65 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PROJ_IGNORE_CELESTIAL_BODY'] = 'YES' \n",
    "\n",
    "def pixel_to_latlon(ax, proj, x_pixel, y_pixel):\n",
    "    # Transform pixel to data coordinates\n",
    "    x_data, y_data  = ax.transData.inverted().transform((x_pixel, y_pixel))\n",
    "     \n",
    "    # Transform data coordinates to geographic coordinates\n",
    "    lon, lat = proj.transform_point(x_data, y_data, src_crs=ax.projection)\n",
    "    coords = ax.format_coord(lon, lat).split('(')[1].split(')')[0]\n",
    "    return coords\n",
    "\n",
    "def get_files_to_dataframe(folder_path):\n",
    "    file_data = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        with fits.open(file_path) as hdu_list:\n",
    "            lat = hdu_list[16].data['PIXEL_CORNER_LAT'][:,:,-1]\n",
    "            lon = hdu_list[16].data['PIXEL_CORNER_LON'][:,:,-1]\n",
    "            solar_zenith_angle = hdu_list[16].data['PIXEL_SOLAR_ZENITH_ANGLE']\n",
    "            emission_angle = hdu_list[16].data['PIXEL_EMISSION_ANGLE']\n",
    "            zenith_angle = hdu_list[16].data['PIXEL_ZENITH_ANGLE']\n",
    "            phase_angle = hdu_list[16].data['PIXEL_PHASE_ANGLE']\n",
    "            local_time = hdu_list[16].data['PIXEL_LOCAL_TIME']\n",
    "            sspacecraft_lat = hdu_list[15].data['SUB_SPACECRAFT_LAT'][0]\n",
    "            sspacecraft_lon = hdu_list[15].data['SUB_SPACECRAFT_LON'][0]\n",
    "            sspacecraft_alt = hdu_list[15].data['SPACECRAFT_ALT'][0]\n",
    "\n",
    "\n",
    "            # Stack and reshape coordinates\n",
    "            z = np.stack([lat, lon], axis=-1)\n",
    "            flattened = z.reshape(-1, 2)\n",
    "            # Convert longitude from 0-360 to -180-180\n",
    "            flattened[:, 1] = (flattened[:, 1] - 180)\n",
    "            all_coords = flattened.tolist()\n",
    "            \n",
    "\n",
    "            y = np.stack([lat, lon, solar_zenith_angle, emission_angle,zenith_angle,phase_angle,local_time], axis=-1)\n",
    "            y = y.tolist()\n",
    "\n",
    "\n",
    "            file_data.append({\n",
    "                'file_name': filename,\n",
    "                'orbit_no': filename.split(\"orbit\")[1].split(\"-\")[0],\n",
    "                'timestamp': filename.split(\"muv_\")[1].split(\"_\")[0],\n",
    "                'sspacecraft_lat': sspacecraft_lat,\n",
    "                'sspacecraft_lon': sspacecraft_lon,\n",
    "                'sspacecraft_alt': sspacecraft_alt* 10 ** 3,\n",
    "                'all_coordinates': all_coords,  # New field containing all points,\n",
    "                'all_columns_data': y\n",
    "            })\n",
    "            \n",
    "\n",
    "    df = pd.DataFrame(file_data)\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], format='%Y%m%dT%H%M%S')\n",
    "    return df\n",
    "\n",
    "def dms_to_decimal(coord):\n",
    "    \"\"\"\n",
    "    Convert coordinate string (e.g., \"27.915383°S\") to decimal float\n",
    "    Returns: float in [-180, 180] for longitude, [-90, 90] for latitude\n",
    "    \"\"\"\n",
    "    if pd.isna(coord) or coord == '':\n",
    "        return np.nan\n",
    "    \n",
    "    # Remove degree symbol and split direction\n",
    "    value = coord.replace('°', '').replace('\"', '').replace(\"'\", '')\n",
    "    direction = value[-1]\n",
    "    number = float(value[:-1])\n",
    "    \n",
    "    # Apply sign based on direction\n",
    "    if direction in ['S', 'W']:\n",
    "        return -number\n",
    "    return number\n",
    "    \n",
    "def plot_all_files_on_globe(parsed_file, df, orbit_no, df_with_coords):\n",
    "    max_files=28\n",
    "    if len(df) == 0:\n",
    "        print(\"DataFrame is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Limit number of files to display\n",
    "    if len(df) > max_files:\n",
    "        print(f\"Showing first {max_files} files out of {len(df)}\")\n",
    "        df = df.head(max_files)\n",
    "        # Make a bounding box such that the image represents 8000 km x 8000 km\n",
    "    rmars = 3400 * 10 ** 3\n",
    "    image_width = 4000 * 10 ** 3\n",
    "    corner_pos = (1 - rmars / image_width) / 2\n",
    "    bbox = (corner_pos, corner_pos, 1 - 2 * corner_pos, 1 - 2 * corner_pos)\n",
    "\n",
    "    # Make properties of the image\n",
    "    dpi = 100  # Adjust DPI if needed\n",
    "    fig = plt.figure(figsize=(1015/dpi, 1015/dpi), dpi=dpi)\n",
    "    globe = ccrs.Globe(semimajor_axis=rmars, semiminor_axis=rmars)\n",
    "    projection=ccrs.NearsidePerspective(\n",
    "        satellite_height=files_df['sspacecraft_alt'].iloc[len(files_df)//2],\n",
    "        central_longitude=files_df['sspacecraft_lon'].iloc[len(files_df)//2]-180, \n",
    "        central_latitude=files_df['sspacecraft_lat'].iloc[len(files_df)//2], globe=globe)\n",
    "    ax = plt.axes()\n",
    "    transform = ccrs.PlateCarree(globe=globe)\n",
    "    ax = plt.axes(bbox, projection=projection)\n",
    "    \n",
    "    # Create a custom colormap with distinct colors\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(df)))\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    # Create legend handles\n",
    "    legend_handles = []\n",
    "    \n",
    "    # Plot each file's data\n",
    "    for idx, (_, row) in enumerate(df.iterrows()):\n",
    "        all_coords = np.array(row['all_coordinates'])\n",
    "        color = colors[idx]\n",
    "        \n",
    "        # Plot all points\n",
    "        ax.scatter(all_coords[:, 1], all_coords[:, 0],\n",
    "                  color=color, s=8, alpha=0.03,\n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  zorder=4)\n",
    "\n",
    "    \n",
    "    classified_coords = parsed_file.loc[parsed_file['subject_data.orbit'] == orbit_no]\n",
    "    classified_coords = classified_coords[['ID','annotations_1.value.x', 'annotations_1.value.y','annotations_1.value.tool_label']]\n",
    "    classified_coords['annotations_1.value.y'] = 1015 - classified_coords['annotations_1.value.y']\n",
    "    classified_coords = classified_coords[classified_coords[['ID','annotations_1.value.x', 'annotations_1.value.y' ,'annotations_1.value.tool_label']].notnull().all(1)]\n",
    "    classified_coords['annotations_1.value.tool_label'] = classified_coords['annotations_1.value.tool_label'].str.split('!').str[0]\n",
    "    classified_coords['projection_globe_coords'] = classified_coords.apply(lambda row: pixel_to_latlon(ax,\n",
    "                                                                                                       projection,\n",
    "                                                                                                       row['annotations_1.value.x'],\n",
    "                                                                                                       row['annotations_1.value.y']), axis=1)\n",
    "    classified_coords[['projection_globe_coords_y', 'projection_globe_coords_x']] = classified_coords['projection_globe_coords'].str.split(',', expand=True)\n",
    "    classified_coords = classified_coords.drop(columns=['projection_globe_coords'])\n",
    "    \n",
    "    df_with_coords = classified_coords[['ID','projection_globe_coords_y', 'projection_globe_coords_x']]\n",
    "    return df_with_coords\n",
    "    \n",
    "\n",
    "\n",
    "columns = ['ID', 'projection_globe_coords_y', 'projection_globe_coords_x']\n",
    "df_with_coords = pd.DataFrame(columns=columns)\n",
    "rows_list = []\n",
    "\n",
    "for orbit_no in orbit_list:\n",
    "    try:\n",
    "        print(f'processing orbit {orbit_no}')\n",
    "        ###----CHANGE THIS ONE---\n",
    "        folder_path = rf'C:\\Users\\lesze\\orbitfolder\\orbit{orbit_no}'\n",
    "        files_df = get_files_to_dataframe(folder_path)\n",
    "        new_coords = plot_all_files_on_globe(parsed_file, files_df, orbit_no, df_with_coords)\n",
    "        df_with_coords = pd.concat([df_with_coords, new_coords], ignore_index=True)\n",
    "        \n",
    "        new_coords['projection_globe_coords_y'] =  new_coords['projection_globe_coords_y'].apply(dms_to_decimal)\n",
    "        new_coords['projection_globe_coords_x'] =  new_coords['projection_globe_coords_x'].apply(dms_to_decimal)\n",
    "    \n",
    "        pre_exploded_df = files_df[['file_name', 'orbit_no', 'timestamp', 'sspacecraft_lat',\n",
    "               'sspacecraft_lon', 'sspacecraft_alt',\n",
    "               'all_columns_data', 'datetime']]\n",
    "        exploded_df = pre_exploded_df.explode('all_columns_data').explode('all_columns_data')\n",
    "        \n",
    "        coord_columns = ['lat', 'lon','solar_zenith_angle', 'emission_angle','zenith_angle','phase_angle','local_time']\n",
    "        exploded_df[coord_columns] = pd.DataFrame(\n",
    "            exploded_df['all_columns_data'].tolist(),\n",
    "            index=exploded_df.index\n",
    "        )\n",
    "        exploded_df['lon'] = (exploded_df['lon'] - 180) \n",
    "    \n",
    "        \n",
    "        for i in range(len(new_coords)):\n",
    "            target_lat = new_coords.iloc[i]['projection_globe_coords_x']\n",
    "            target_lon = new_coords.iloc[i]['projection_globe_coords_y']\n",
    "        \n",
    "            # Calculate distances\n",
    "            exploded_df['distance'] = np.sqrt(\n",
    "                (exploded_df['lat'] - target_lat)**2 + \n",
    "                (exploded_df['lon'] - target_lon)**2\n",
    "            )\n",
    "            \n",
    "            # Get closest row (as Series)\n",
    "            closest_row = exploded_df.nsmallest(1, 'distance').iloc[0]\n",
    "            \n",
    "            # Combine data into a single dictionary\n",
    "            combined_data = {\n",
    "                **new_coords.iloc[i].to_dict(),\n",
    "                **{f'closest_{k}': v for k, v in closest_row.to_dict().items()}\n",
    "            }\n",
    "            \n",
    "            rows_list.append(combined_data)\n",
    "    except:        \n",
    "        print(f'Error processing orbit: {orbit_no}. Most likely missing FITS files or no classifications for this orbit. Check it')\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(rows_list)\n",
    "\n",
    "classifications_with_coordinates = parsed_file.merge(\n",
    "result_df,\n",
    "on='ID',  # or left_on/right_on if column names differ\n",
    "how='inner'       # keeps all rows from parsed_file\n",
    ")\n",
    "\n",
    "classifications_with_coordinates.drop(['closest_all_columns_data', 'closest_timestamp', 'closest_orbit_no'], axis=1) #remove unnecassary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "733fb0f3-ef74-4b98-8196-f79b0a653f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_POINTS = 0\n",
    "MIN_UNIQUE_USERS = 5\n",
    "\n",
    "def get_cluster_dataframe(points, cloud_types, weights, user_names, orbit_no, original_df):\n",
    "    \"\"\"Identify clusters and create dataframe with weighted dominant type calculation.\"\"\"\n",
    "    if len(points) < MIN_POINTS:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    X = np.array(points)\n",
    "    cloud_types = np.array(cloud_types)\n",
    "    weights = np.array(weights)\n",
    "    user_names = np.array(user_names)\n",
    "    \n",
    "    radius_rules = {\n",
    "        'Disk Clouds': 30,\n",
    "        'Dotted Clouds': 30,\n",
    "        'Dotted Cloud': 30,\n",
    "        'Streak Clouds': 50,\n",
    "        'Streak Cloud': 50,\n",
    "        'Vortex Clouds': 50,\n",
    "        'Twilight Clouds': 50,\n",
    "        'Gravity Waves': 30\n",
    "    }\n",
    "    \n",
    "    point_radii = np.array([radius_rules.get(ctype.strip(), 30) * weights[i] \n",
    "                         for i, ctype in enumerate(cloud_types)])\n",
    "    \n",
    "    labels = np.full(len(X), -1)\n",
    "    current_label = 0\n",
    "    cluster_data = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        if labels[i] != -1:\n",
    "            continue\n",
    "            \n",
    "        distances = np.sqrt(np.sum((X - X[i])**2, axis=1))\n",
    "        neighbors = np.where((distances <= point_radii[i]) & (labels == -1))[0]\n",
    "        \n",
    "        if len(neighbors) >= MIN_POINTS:\n",
    "            unique_users = list(set(user_names[neighbors]))\n",
    "            if len(unique_users) >= MIN_UNIQUE_USERS:\n",
    "                # Calculate weighted votes for each cloud type\n",
    "                weighted_votes = {}\n",
    "                for idx in neighbors:\n",
    "                    ctype = cloud_types[idx]\n",
    "                    weight = weights[idx]\n",
    "                    weighted_votes[ctype] = weighted_votes.get(ctype, 0) + weight\n",
    "                if weighted_votes:\n",
    "                    # Get dominant type based on weighted votes\n",
    "                    dominant_type = max(weighted_votes.items(), key=lambda x: x[1])[0]\n",
    "                    total_weight = sum(weighted_votes.values())\n",
    "                    confidence = weighted_votes[dominant_type] / total_weight\n",
    "                    dominant_radius = radius_rules.get(dominant_type, 30)\n",
    "                    \n",
    "                    labels[neighbors] = current_label\n",
    "                    center = np.mean(X[neighbors], axis=0)\n",
    "                    \n",
    "                    # Generate cluster name (A, B, ..., Z, AA, AB, etc.)\n",
    "                    cluster_name = ''\n",
    "                    n = current_label\n",
    "                    while n >= 0:\n",
    "                        cluster_name = chr(ord('A') + n % 26) + cluster_name\n",
    "                        n = n // 26 - 1\n",
    "                    \n",
    "                    # Create cluster info dictionary\n",
    "                    cluster_data.append({\n",
    "                        'orbit_no': orbit_no,\n",
    "                        'cluster_name': cluster_name,\n",
    "                        'cluster_center_x': center[0],\n",
    "                        'cluster_center_y': center[1],\n",
    "                        'cluster_cloud_type': dominant_type,\n",
    "                        'cluster_user_count': len(unique_users),\n",
    "                        'cluster_confidence': confidence,  # Weighted confidence\n",
    "                        'cluster_radius': dominant_radius,\n",
    "                        'cluster_total_weight': total_weight,  # Added total weight info\n",
    "                        'cluster_weighted_votes': weighted_votes\n",
    "                    })\n",
    "            \n",
    "                    current_label += 1\n",
    "    \n",
    "    return pd.DataFrame(cluster_data)\n",
    "\n",
    "def process_orbit_data(parsed_file, orbit_no):\n",
    "    \"\"\"\n",
    "    Process data for a specific orbit and return combined DataFrame.\n",
    "    \"\"\"\n",
    "    df = parsed_file.loc[parsed_file['subject_data.orbit'] == orbit_no].copy()\n",
    "    \n",
    "    cols = ['ID', 'user_name', 'annotations_1.value.x', 'annotations_1.value.y', \n",
    "            'annotations_1.value.tool_label', 'weight']\n",
    "    df = df[cols][df[cols].notnull().all(1)]\n",
    "    df['Cloud type'] = df['annotations_1.value.tool_label'].str.split('!').str[0].str.strip()\n",
    "    df['annotations_1.value.y'] = df['annotations_1.value.y']\n",
    "    df['weight'] = pd.to_numeric(df['weight'])\n",
    "    \n",
    "    points = df[['annotations_1.value.x', 'annotations_1.value.y']].values\n",
    "    cloud_types = df['Cloud type'].values\n",
    "    weights = df['weight'].values\n",
    "    user_names = df['user_name'].values\n",
    "    \n",
    "    return get_cluster_dataframe(points, cloud_types, weights, user_names, orbit_no, df)\n",
    "\n",
    "def process_all_orbits(parsed_file, orbit_list, logged_in_users=True):\n",
    "    \"\"\"\n",
    "    Process multiple orbits and return concatenated DataFrame with all data.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for orbit_no in orbit_list:\n",
    "        orbit_data = process_orbit_data(parsed_file, orbit_no)\n",
    "        if not orbit_data.empty:\n",
    "            all_data.append(orbit_data)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Usage example:\n",
    "# orbit_list = [16570, 16571, 16572]  # Your orbit numbers\n",
    "all_clusters_df = process_all_orbits(classifications_with_coordinates, orbit_list)\n",
    "all_clusters_df.to_csv('cloud_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2cf05cae-c9d0-4f28-9ae7-84a464e9ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orbit_no</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>cluster_center_x</th>\n",
       "      <th>cluster_center_y</th>\n",
       "      <th>cluster_cloud_type</th>\n",
       "      <th>cluster_user_count</th>\n",
       "      <th>cluster_confidence</th>\n",
       "      <th>cluster_radius</th>\n",
       "      <th>cluster_total_weight</th>\n",
       "      <th>cluster_weighted_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17959</td>\n",
       "      <td>A</td>\n",
       "      <td>295.260276</td>\n",
       "      <td>363.715119</td>\n",
       "      <td>Streak Clouds</td>\n",
       "      <td>5</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>50</td>\n",
       "      <td>98</td>\n",
       "      <td>{'Streak Clouds': 85, 'Gravity Waves': 12, 'Vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17959</td>\n",
       "      <td>B</td>\n",
       "      <td>782.181671</td>\n",
       "      <td>347.696518</td>\n",
       "      <td>Dotted Clouds</td>\n",
       "      <td>5</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>{'Dotted Clouds': 9, 'Gravity Waves': 4, 'Stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16570</td>\n",
       "      <td>A</td>\n",
       "      <td>447.313565</td>\n",
       "      <td>669.173754</td>\n",
       "      <td>Disk Clouds</td>\n",
       "      <td>5</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>30</td>\n",
       "      <td>86</td>\n",
       "      <td>{'Disk Clouds': 58, 'Streak Clouds': 6, 'Other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16570</td>\n",
       "      <td>B</td>\n",
       "      <td>439.710783</td>\n",
       "      <td>520.007529</td>\n",
       "      <td>Streak Clouds</td>\n",
       "      <td>6</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "      <td>{'Vortex Clouds': 5, 'Twilight Clouds': 2, 'St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orbit_no cluster_name  cluster_center_x  cluster_center_y  \\\n",
       "0     17959            A        295.260276        363.715119   \n",
       "1     17959            B        782.181671        347.696518   \n",
       "2     16570            A        447.313565        669.173754   \n",
       "3     16570            B        439.710783        520.007529   \n",
       "\n",
       "  cluster_cloud_type  cluster_user_count  cluster_confidence  cluster_radius  \\\n",
       "0      Streak Clouds                   5            0.867347              50   \n",
       "1      Dotted Clouds                   5            0.409091              30   \n",
       "2        Disk Clouds                   5            0.674419              30   \n",
       "3      Streak Clouds                   6            0.652174              50   \n",
       "\n",
       "   cluster_total_weight                             cluster_weighted_votes  \n",
       "0                    98  {'Streak Clouds': 85, 'Gravity Waves': 12, 'Vo...  \n",
       "1                    22  {'Dotted Clouds': 9, 'Gravity Waves': 4, 'Stre...  \n",
       "2                    86  {'Disk Clouds': 58, 'Streak Clouds': 6, 'Other...  \n",
       "3                    69  {'Vortex Clouds': 5, 'Twilight Clouds': 2, 'St...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2485150-36ac-4942-8c2a-439bd4d2ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def join_closest(df_clusters, df_classifications):\n",
    "    # Create an empty list to store the joined rows\n",
    "    joined_rows = []\n",
    "    \n",
    "    for _, cluster_row in df_clusters.iterrows():\n",
    "        orbit = cluster_row['orbit_no']\n",
    "        center_x = cluster_row['cluster_center_x']\n",
    "        center_y = cluster_row['cluster_center_y']\n",
    "        \n",
    "        # Filter classifications for this orbit\n",
    "        classifications = df_classifications[df_classifications['subject_data.orbit'] == orbit].copy()\n",
    "        \n",
    "        if not classifications.empty:\n",
    "            # Calculate distance from cluster center to each point\n",
    "            classifications['distance'] = np.sqrt(\n",
    "                (classifications['annotations_1.value.y'] - center_x)**2 + \n",
    "                (classifications['annotations_1.value.x'] - center_y)**2\n",
    "            )\n",
    "            \n",
    "            # Find the row with minimum distance\n",
    "            closest_row = classifications.loc[classifications['distance'].idxmin()]\n",
    "            \n",
    "            # Combine cluster and classification data\n",
    "            joined_row = {**cluster_row.to_dict(), **closest_row.to_dict()}\n",
    "            joined_rows.append(joined_row)\n",
    "    \n",
    "    # Create DataFrame from joined rows\n",
    "    return pd.DataFrame(joined_rows)\n",
    "\n",
    "# Usage:\n",
    "result_df = join_closest(all_clusters_df, classifications_with_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf3f0f96-f2a8-4b25-8680-52fe8a463f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   orbit_no cluster_name  cluster_center_x  cluster_center_y  \\\n",
      "0     17959            A        295.260276        363.715119   \n",
      "1     17959            B        782.181671        347.696518   \n",
      "2     16570            A        447.313565        669.173754   \n",
      "3     16570            B        439.710783        520.007529   \n",
      "\n",
      "  cluster_cloud_type  cluster_user_count  cluster_confidence  cluster_radius  \\\n",
      "0      Streak Clouds                   5            0.867347              50   \n",
      "1      Dotted Clouds                   5            0.409091              30   \n",
      "2        Disk Clouds                   5            0.674419              30   \n",
      "3      Streak Clouds                   6            0.652174              50   \n",
      "\n",
      "   cluster_total_weight                             cluster_weighted_votes  \\\n",
      "0                    98  {'Streak Clouds': 85, 'Gravity Waves': 12, 'Vo...   \n",
      "1                    22  {'Dotted Clouds': 9, 'Gravity Waves': 4, 'Stre...   \n",
      "2                    86  {'Disk Clouds': 58, 'Streak Clouds': 6, 'Other...   \n",
      "3                    69  {'Vortex Clouds': 5, 'Twilight Clouds': 2, 'St...   \n",
      "\n",
      "                            user_name    user_id               user_ip  \\\n",
      "0  not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
      "1  not-logged-in-950908914f5575dc1433        NaN  950908914f5575dc1433   \n",
      "2                          Leslye2030  2749879.0  436f5d6a3bb62c2daa35   \n",
      "3  not-logged-in-2adc44cb9de64ca821bc        NaN  2adc44cb9de64ca821bc   \n",
      "\n",
      "   workflow_id        workflow_name  workflow_version          created_at  \\\n",
      "0        26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
      "1        26820  Are Clouds Present?             40.87 2024-11-10 23:41:47   \n",
      "2        26820  Are Clouds Present?             40.87 2024-12-26 01:14:45   \n",
      "3        26820  Are Clouds Present?             40.87 2024-12-17 21:03:31   \n",
      "\n",
      "   subject_ids                                   metadata.session  \\\n",
      "0    104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
      "1    104284703  05f8a2d52ef7b2fedb92131598bbe7952b4500964c4bcf...   \n",
      "2    104284523  6e7c59d2b9e2c62426f0c36229e74582212cffdfff4680...   \n",
      "3    104284523  a9b7ea9437f01b5e5a0d86a075e543b2a8d9936f4d1f29...   \n",
      "\n",
      "        metadata.started_at  \\\n",
      "0  2024-11-10T23:30:13.622Z   \n",
      "1  2024-11-10T23:30:13.622Z   \n",
      "2  2024-12-26T01:13:29.812Z   \n",
      "3  2024-12-17T20:50:27.813Z   \n",
      "\n",
      "                                 metadata.user_agent  metadata.utc_offset  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...               -32400   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...               -32400   \n",
      "2  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                18000   \n",
      "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...                18000   \n",
      "\n",
      "       metadata.finished_at metadata.user_language metadata.user_group_ids  \\\n",
      "0  2024-11-10T23:41:46.767Z                     en                     NaN   \n",
      "1  2024-11-10T23:41:46.767Z                     en                     NaN   \n",
      "2  2024-12-26T01:14:42.491Z                     en               [2698480]   \n",
      "3  2024-12-17T21:03:30.846Z                     en                     NaN   \n",
      "\n",
      "   metadata.workflow_translation_id  metadata.viewport.width  \\\n",
      "0                           74181.0                     1920   \n",
      "1                           74181.0                     1920   \n",
      "2                           74181.0                     1920   \n",
      "3                           74181.0                     1485   \n",
      "\n",
      "   metadata.viewport.height  metadata.interventions.opt_in  \\\n",
      "0                       911                          False   \n",
      "1                       911                          False   \n",
      "2                       945                           True   \n",
      "3                       890                          False   \n",
      "\n",
      "   metadata.interventions.messageShown  \\\n",
      "0                                False   \n",
      "1                                False   \n",
      "2                                False   \n",
      "3                                False   \n",
      "\n",
      "   metadata.subject_selection_state.retired  \\\n",
      "0                                     False   \n",
      "1                                     False   \n",
      "2                                     False   \n",
      "3                                     False   \n",
      "\n",
      "  metadata.subject_selection_state.selected_at  \\\n",
      "0                     2024-11-10T23:30:13.247Z   \n",
      "1                     2024-11-10T23:30:13.247Z   \n",
      "2                     2024-12-26T01:04:16.687Z   \n",
      "3                     2024-12-17T20:50:27.791Z   \n",
      "\n",
      "   metadata.subject_selection_state.already_seen  \\\n",
      "0                                          False   \n",
      "1                                          False   \n",
      "2                                          False   \n",
      "3                                          False   \n",
      "\n",
      "  metadata.subject_selection_state.selection_state  \\\n",
      "0                                           normal   \n",
      "1                                           normal   \n",
      "2                                           normal   \n",
      "3                                           normal   \n",
      "\n",
      "   metadata.subject_selection_state.finished_workflow  \\\n",
      "0                                              False    \n",
      "1                                              False    \n",
      "2                                              False    \n",
      "3                                              False    \n",
      "\n",
      "   metadata.subject_selection_state.user_has_finished_workflow  \\\n",
      "0                                              False             \n",
      "1                                              False             \n",
      "2                                              False             \n",
      "3                                              False             \n",
      "\n",
      "   metadata.seen_before  metadata.subject_dimensions.clientWidth  \\\n",
      "0                   NaN                                    545.0   \n",
      "1                   NaN                                    545.0   \n",
      "2                   NaN                                    851.0   \n",
      "3                   NaN                                    801.0   \n",
      "\n",
      "   metadata.subject_dimensions.clientHeight  \\\n",
      "0                                     545.0   \n",
      "1                                     545.0   \n",
      "2                                     851.0   \n",
      "3                                     801.0   \n",
      "\n",
      "   metadata.subject_dimensions.naturalWidth  \\\n",
      "0                                    1015.0   \n",
      "1                                    1015.0   \n",
      "2                                    1015.0   \n",
      "3                                    1015.0   \n",
      "\n",
      "   metadata.subject_dimensions.naturalHeight  subject_data.orbit  \\\n",
      "0                                     1015.0               17959   \n",
      "1                                     1015.0               17959   \n",
      "2                                     1015.0               16570   \n",
      "3                                     1015.0               16570   \n",
      "\n",
      "   subject_data.Ls  subject_data.Angle  subject_data.Binning  \\\n",
      "0              399                 399                   133   \n",
      "1              399                 399                   133   \n",
      "2              822                 822                   133   \n",
      "3              822                 822                   133   \n",
      "\n",
      "                            annotations_0.task_label  \\\n",
      "0  Are there clouds in this image?\\n\\nWe will go ...   \n",
      "1  Are there clouds in this image?\\n\\nWe will go ...   \n",
      "2  Are there clouds in this image?\\n\\nWe will go ...   \n",
      "3  Are there clouds in this image?\\n\\nWe will go ...   \n",
      "\n",
      "                                 annotations_0.value  \\\n",
      "0  Yes, there are distinct cloud shapes and gener...   \n",
      "1  Yes, there are distinct cloud shapes and gener...   \n",
      "2               Yes, there are distinct cloud shapes   \n",
      "3               Yes, there are distinct cloud shapes   \n",
      "\n",
      "                                       annotations_1  \\\n",
      "0  {'task': 'T2', 'task_label': \"Mark where you s...   \n",
      "1  {'task': 'T2', 'task_label': \"Mark where you s...   \n",
      "2  {'task': 'T2', 'task_label': \"Mark where you s...   \n",
      "3  {'task': 'T2', 'task_label': \"Mark where you s...   \n",
      "\n",
      "                            annotations_1.task_label  annotations_1.value.x  \\\n",
      "0  Mark where you see a distinct cloud shape(s).\\...             378.199829   \n",
      "1  Mark where you see a distinct cloud shape(s).\\...             312.587433   \n",
      "2  Mark where you see a distinct cloud shape(s).\\...             615.560059   \n",
      "3  Mark where you see a distinct cloud shape(s).\\...             530.208984   \n",
      "\n",
      "   annotations_1.value.y  annotations_1.value.tool  annotations_1.value.frame  \\\n",
      "0             283.437103                       4.0                        0.0   \n",
      "1             821.954041                       2.0                        0.0   \n",
      "2             561.203674                       4.0                        0.0   \n",
      "3             508.255646                       6.0                        0.0   \n",
      "\n",
      "  annotations_1.value.details  \\\n",
      "0                          []   \n",
      "1                          []   \n",
      "2                          []   \n",
      "3                          []   \n",
      "\n",
      "                      annotations_1.value.tool_label  \\\n",
      "0  Gravity Waves\\n![gravitywaves small.png](https...   \n",
      "1  Streak Clouds\\n![streaks small.png](https://pa...   \n",
      "2  Gravity Waves\\n![gravitywaves small.png](https...   \n",
      "3                         Other (not specified here)   \n",
      "\n",
      "                             orbit+username  user_orbit_counts     rank  \\\n",
      "0  17959+not-logged-in-950908914f5575dc1433                197    elite   \n",
      "1  17959+not-logged-in-950908914f5575dc1433                197    elite   \n",
      "2                          16570+Leslye2030                 11  student   \n",
      "3  16570+not-logged-in-2adc44cb9de64ca821bc                123    elite   \n",
      "\n",
      "   weight     ID  projection_globe_coords_y  projection_globe_coords_x  \\\n",
      "0       3  31401                  59.356021                 -65.127406   \n",
      "1       3  31537                   5.416390                 -61.473858   \n",
      "2       1  85427                 -75.981778                 -79.063150   \n",
      "3       3  78062                 -74.681310                -112.771371   \n",
      "\n",
      "                                   closest_file_name closest_orbit_no  \\\n",
      "0  mvn_iuv_l1b_apoapse-orbit17959-muv_20230107T21...            17959   \n",
      "1  mvn_iuv_l1b_apoapse-orbit17959-muv_20230107T21...            17959   \n",
      "2  mvn_iuv_l1b_apoapse-orbit16570-muv_20220611T01...            16570   \n",
      "3  mvn_iuv_l1b_apoapse-orbit16570-muv_20220611T01...            16570   \n",
      "\n",
      "  closest_timestamp  closest_sspacecraft_lat  closest_sspacecraft_lon  \\\n",
      "0   20230107T215511                19.216661               136.720755   \n",
      "1   20230107T215511                19.216661               136.720755   \n",
      "2   20220611T012256               -73.846177                71.635722   \n",
      "3   20220611T011534               -74.898798                50.913097   \n",
      "\n",
      "   closest_sspacecraft_alt                           closest_all_columns_data  \\\n",
      "0             4.133966e+06  [-28.61014372327816, 177.4570715633113, 36.834...   \n",
      "1             4.133966e+06  [-34.391805937354945, 169.44387840357723, 38.7...   \n",
      "2             4.348811e+06  [-79.20008862909992, 103.94819706929626, 72.76...   \n",
      "3             4.354981e+06  [-89.59350269425313, 105.85717314252547, 67.58...   \n",
      "\n",
      "     closest_datetime  closest_lat  closest_lon  closest_solar_zenith_angle  \\\n",
      "0 2023-01-07 21:55:11   -28.610144    -2.542928                   36.834445   \n",
      "1 2023-01-07 21:55:11   -34.391806   -10.556122                   38.762498   \n",
      "2 2022-06-11 01:22:56   -79.200089   -76.051803                   72.768435   \n",
      "3 2022-06-11 01:15:34   -89.593503   -74.142827                   67.587520   \n",
      "\n",
      "   closest_emission_angle  closest_zenith_angle  closest_phase_angle  \\\n",
      "0               89.999995            153.438661            53.533081   \n",
      "1               89.999995            153.430806            52.722058   \n",
      "2               15.907407            173.137139            88.391301   \n",
      "3               25.940654            168.992832            93.287106   \n",
      "\n",
      "   closest_local_time  closest_distance    distance  \n",
      "0           13.355971         71.867868   18.697439  \n",
      "1           12.815538         31.441353   53.051760  \n",
      "2            4.131072          0.153804  125.878454  \n",
      "3            4.147274         23.184123   69.299841  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 80):\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2129ad52-4af5-4595-ba68-a2f7a8a04a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('cloud_clusters_enchanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8084a0-a9d9-47f3-a956-5f060f0a14e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
